{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "Entrez.api_key = \"\"\n",
    "Entrez.email = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparse complete plamisd sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genbank file to annotation(per sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Seq_Record in SeqIO.parse(\"../../biopython/ndm_all_gb.gb\",\"genbank\"):\n",
    "    id=Seq_Record.name\n",
    "    for feature in Seq_Record.features:\n",
    "        if feature.type == \"source\":\n",
    "            host=feature.qualifiers.get(\"host\")\n",
    "            country=feature.qualifiers.get(\"country\")\n",
    "            date=feature.qualifiers.get(\"collection_date\")\n",
    "            plasmid=feature.qualifiers.get(\"plasmid\")\n",
    "            organism=feature.qualifiers.get(\"organism\")\n",
    "    try:\n",
    "        with open ('./complete/annotation/'+str(organism)+'.'+str(host)+'.'+str(country)+'.'+str(date)+'.'+str(plasmid)+'.'+str(id)+'.tsv','w') as handle:\n",
    "            handle.write(\"location\\tproduct\\n\")\n",
    "        with open ('./complete/annotation/'+str(organism)+'.'+str(host)+'.'+str(country)+'.'+str(date)+'.'+str(plasmid)+'.'+str(id)+'.tsv','a') as handle:\n",
    "            for feature in Seq_Record.features:\n",
    "                if feature.type == \"CDS\":  \n",
    "            #if feature.qualifiers.get(\"product\") == ['blaNDM-5']:\n",
    "            #handle.write(\"{}\\t{}\\t{}\\n\".format(Seq_Record.id,feature.qualifiers.get(\"protein_id\"),feature.qualifiers.get(\"translation\")))\n",
    "                    handle.write(\"{}\\t{}\\n\".format(feature.location,feature.qualifiers.get(\"product\"))) \n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## give group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./complete/annotation/;\n",
    "for n in {A..Z}\n",
    "do \n",
    "mkdir ../groupby/${n}/\n",
    "cp ./[\\'${n}* ../groupby/${n}/\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./complete/groupby/;\n",
    "find -type d -empty | xargs rm -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ./complete/groupby/;\n",
    "num=1;\n",
    "dir=$(ls)\n",
    "for n in $dir\n",
    "do \n",
    "ls ${n} >> ${num}.txt\n",
    "sed -i 's/.tsv//g' ${num}.txt\n",
    "num=$(($num+1))\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output group csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "group_name=1\n",
    "\n",
    "while (group_name < 11):\n",
    "    with open('./complete/groupby/'+str(group_name)+'.txt','r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tsv=pd.read_table('./complete/annotation/'+str(line)+'.tsv')\n",
    "            #print(tsv[tsv['product']=='Metallo-beta-lactamase type 2'])\n",
    "            ndm_index=tsv[tsv[\"product\"].str.contains('NDM|ndm|metallo-beta-lactamase|Metallo-beta-lactamase')].index.tolist()\n",
    "            ndm_pi=[ndm - 20 if ndm >20 else 0 for ndm in ndm_index]\n",
    "            ndm_ai=[ndm + 21 if ndm+21 < tsv.shape[0] else tsv.shape[0] for ndm in ndm_index]\n",
    "            for pi,ai in zip(ndm_pi,ndm_ai):\n",
    "                df=tsv.iloc[pi:ai]\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                #dfdf[df['product']=='Metallo-beta-lactamase type 2'].index.array\n",
    "                ndm_df_index=df[df[\"product\"].str.contains('NDM|ndm|metallo-beta-lactamase|Metallo-beta-lactamase')].index.array[0]\n",
    "                if \"-\" in df.iloc[ndm_df_index,0]:\n",
    "                    df=df.iloc[::-1]\n",
    "                df=df[\"product\"].to_frame()\n",
    "                #print(df)\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                ndm_df_index=df[df[\"product\"].str.contains('NDM|ndm|metallo-beta-lactamase|Metallo-beta-lactamase')].index.array[0]\n",
    "                add_row=20-ndm_df_index\n",
    "                for i in range(add_row):\n",
    "                    df.loc[str(i)]='0'\n",
    "                df=df.shift(periods=add_row,axis=0,fill_value=0)\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                df=df.T\n",
    "                df.rename(index={'product':str(line)},inplace=True)\n",
    "                df.to_csv('./complete/csvgroup/20/'+str(group_name)+'.csv', mode='a', header=False)\n",
    "    group_name+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spare assembly plasmid sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network file to clique group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gml_graph = nx.read_gml('./test file/m4all_ndm2.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndm_clique=list(nx.find_cliques(gml_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndm_include_clique = [clique for clique in ndm_clique if 'blaNDM-1' in clique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./assembly/ndm_include_clique'+'.txt','w') as f:\n",
    "        f.write(\"{}\\n\".format(\"\\n\".join(str(i) for i in ndm_include_clique)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequence per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gene_pa=pd.read_table('../output/roary_ndm_assembly_Ecoli/prokka/roary_output2/gene_presence_absence.Rtab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name=0\n",
    "for item in ndm1_include_clique:\n",
    "    I=[]\n",
    "    df=gene_pa[gene_pa.index.isin(item)]\n",
    "    df.drop(['Gene'],axis=1,inplace=True)\n",
    "    for index, col in df.iteritems():\n",
    "        if col.sum() == df.shape[0]:\n",
    "            I.append(index)\n",
    "    #print(\"{}\\n\".format(I))\n",
    "    group_name+=1\n",
    "    with open('./assembly/ndm_group/'+str(group_name)+'.txt','w') as f:\n",
    "        f.write(\"{}\\n\".format(\"\\n\".join(str(i) for i in I)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output group csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /mnt/d/biotools/workshop/ndm_plasmid/output/roary_ndm_assembly_Ecoli/prokka_chro/gff;\n",
    "find -name \"*.gff\" | xargs grep \"NDM\" | cut -f 1,7 > gff.txt;\n",
    "sed -i \"s/.*://g\" gff.txt;\n",
    "echo -e \"name\\tstrand\" > gff_uniq.txt;\n",
    "sort -n gff.txt | uniq >> gff_uniq.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据txt分组名（group name),搜寻每个名字对应的文件tsv,提取其product列，将名称改为其分组名，同一txt的在同一输出文件成行。\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "group_name=1\n",
    "tsv_path='/mnt/d/biotools/workshop/ndm_plasmid/output/roary_ndm_assembly_Ecoli/prokka_chro/test/tsv/'\n",
    "gff_path='/mnt/d/biotools/workshop/ndm_plasmid/output/roary_ndm_assembly_Ecoli/prokka_chro/gff/gff_uniq.txt'\n",
    "\n",
    "while (group_name < 2):\n",
    "    with open('./assembly/ndm_group_chro/'+str(group_name)+'.txt','r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            tsv=pd.read_table(tsv_path+str(line)+'.tsv')\n",
    "            gff=pd.read_table(gff_path)\n",
    "            #print(tsv[tsv['product']=='Metallo-beta-lactamase type 2'])\n",
    "            ndm_index=tsv[tsv['product']=='Metallo-beta-lactamase type 2'].index.tolist()\n",
    "            ndm_pi=[ndm - 10 if ndm >10 else 0 for ndm in ndm_index]\n",
    "            ndm_ai=[ndm + 11 if ndm+11 < tsv.shape[0] else tsv.shape[0] for ndm in ndm_index]\n",
    "            for pi,ai in zip(ndm_pi,ndm_ai):\n",
    "                df=tsv.iloc[pi:ai]\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                #dfdf[df['product']=='Metallo-beta-lactamase type 2'].index.array\n",
    "                \n",
    "                ndm_df_index=df[df['product']=='Metallo-beta-lactamase type 2'].index.array[0]\n",
    "                #print(df.iloc[ndm_df_index,0].split(\"_\")[-2])\n",
    "                ndm_gff_index=gff[gff[\"name\"].str.contains(df.iloc[ndm_df_index,0].split(\"_\")[-2])].index.array[0]\n",
    "                if gff.iloc[ndm_gff_index,1] == \"-\":\n",
    "                    df=df.iloc[::-1]\n",
    "                df=df[\"product\"].to_frame()\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                \n",
    "                ndm_df_index=df[df['product']=='Metallo-beta-lactamase type 2'].index.array[0]\n",
    "                add_row=10-ndm_df_index\n",
    "                for i in range(add_row):\n",
    "                    df.loc[str(i)]='0'\n",
    "                df=df.shift(periods=add_row,axis=0,fill_value=0)\n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                df=df.T\n",
    "                df.rename(index={'product':str(line)},inplace=True)\n",
    "                df.to_csv('./assembly/ndm_group_chro/'+str(group_name)+'.csv', mode='a', header=False)\n",
    "    group_name+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# circos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load ./assembly/A-list.txt\n",
    "chro：Assembly所有染色体GCA号\n",
    "chro1：chro去重复\n",
    "chro_part：GCA每一个独特的基因环境的代表GCA\n",
    "chro_part1：chro_part去重复\n",
    "plasmid：Assembly所有质粒的GCA 号\n",
    "plasmid1：plasmid去重复\n",
    "plasmid_all：Assembly所有质粒的基因环境（已去重复）\n",
    "h：在chro1和plasmid1里都有的GCA号\n",
    "h1：在chro_part1和plasmid1里都有的GCA号\n",
    "comm_p：提取h在质粒plasmid_all的对应质粒条目\n",
    "comm_p1：提取h1在质粒plasmid_all的对应质粒条目\n",
    "comm_c:提取h在染色体chro_all的对应染色体条目\n",
    "comm_c1：提取h1在染色体chro_all的对应染色体条目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_p=pd.read_table('./assembly/comm_p'+'.txt',header=None).dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_c=pd.read_table('./assembly/comm_c'+'.txt',header=None).dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_c=pd.concat([comm_c[:][0].str.split('.',expand=True)[:][0].to_frame(),comm_c.drop([0],axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_p=pd.concat([comm_p[:][0].str.split('.',expand=True)[:][0].to_frame(),comm_p.drop([0],axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_merge=pd.merge(comm_c,comm_p,how='outer',on=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_merge=pc_merge.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_merge=pc_merge.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_merge.to_csv('./assembly/merge'+'.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intra GCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_region=pd.read_table('/mnt/c/Users/Yuing/Desktop/circos_test/ndm_pc/p1'+'.txt',header=None).dropna(how='all',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_region=pd.read_table('/mnt/c/Users/Yuing/Desktop/circos_test/ndm_pc/c1'+'.txt',header=None).dropna(how='all',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_merge=pd.merge(p_region,c_region,how='outer',on=3).dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_merge.loc[:,'0_x'].str.split('_p',expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_GCA=pc_merge[pc_merge.loc[:,'0_x'].str.split('_p',expand=True)[0] == pc_merge.loc[:,'0_y'].str.split('_c',expand=True)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_GCA.iloc[:,[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_GCA.to_csv('/mnt/c/Users/Yuing/Desktop/inner_GCA_links'+'.txt',index=False,sep='\\t',header=False,float_format = '%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_GCA.iloc[:,[0,1,2,4,5,6]].to_csv('/mnt/c/Users/Yuing/Desktop/pclinks'+'.txt',index=False,sep='\\t',header=False,float_format = '%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inter GCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_merge=pd.merge(p_region,p_region,how='outer',on=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_merge1=p_merge[p_merge.loc[:,'0_x'] != p_merge.loc[:,'0_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_merge_list=p_merge1.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1=list(set(_) for _ in p_merge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "l3=[]\n",
    "for i in p_merge_list:\n",
    "    if not set(i) in l3:\n",
    "        l2.append(i)\n",
    "    l3.append(set(i))\n",
    "len(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_p = pd.DataFrame(l2,columns=['1','2','3','4','5','6','7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_p.to_csv('/mnt/c/Users/Yuing/Desktop/pslinks'+'.txt',index=False,sep='\\t',header=False,float_format = '%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_p.iloc[:,[0,1,2,4,5,6]].to_csv('/mnt/c/Users/Yuing/Desktop/iterp_GCA_links'+'.txt',index=False,sep='\\t',header=False,float_format = '%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1=p_region[[3]].append(c_region[[3]]).drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2=['fill_color=chr'+str(n+1) for n in range(47)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2=pd.Series(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=pd.concat([h1,h2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_h = h.set_index(3).T.to_dict('list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_repl=h.set_index(3)[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hightlights=p_region.replace(acc_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_hightlights=c_region.replace(acc_repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hightlights.to_csv('/mnt/c/Users/Yuing/Desktop/p_hightlights'+'.txt',index=False,sep='\\t',header=False,float_format = '%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_hightlights.to_csv('/mnt/c/Users/Yuing/Desktop/c_hightlights'+'.txt',index=False,sep='\\t',header=False,float_format = '%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gene map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='/root/jupyter_projects/ndm_plasmid_2021/input/'\n",
    "dir2='clusters85/'\n",
    "dir_customs=['1','2','3','4','5','6','7','8','9','10','11','12','13','14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndm_all_processed=pd.read_csv('/root/jupyter_projects/ndm_plasmid_2021/input/'+'ndm_all_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndm_species=ndm_all_processed.loc[:][['ACC_NUCCORE','taxon_genus_name','rep2','host_all','Location2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(ndm_species.taxon_genus_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#location\n",
    "\n",
    "sns_colors=sns.color_palette(\"cubehelix\",7).as_hex()[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#host\n",
    "sns_colors=sns.color_palette(\"rocket\").as_hex()[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#rep\n",
    "eight=sns.color_palette(\"Paired\", 12).as_hex()\n",
    "eight\n",
    "\n",
    "seven=sns.color_palette(\"tab10\").as_hex()[1:8]\n",
    "seven\n",
    "\n",
    "sns_colors=eight+seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genus\n",
    "eight=sns.color_palette(\"Set2\", 8).as_hex()\n",
    "eight\n",
    "\n",
    "seven=sns.color_palette(\"Set1\", 15).as_hex()[1:9]\n",
    "seven\n",
    "\n",
    "sns_colors=eight+seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "fig=sns.color_palette(sns_colors)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_sp=pd.DataFrame(pd.Series(sns_colors,uniques),columns=['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_sp['taxon_genus_name'] = colors_sp.index\n",
    "colors_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "a = 3  # number of rows\n",
    "b = 6  # number of columns\n",
    "c = 1  # initialize plot counter\n",
    "plt.figure(figsize=[30,10])\n",
    "\n",
    "#for dir_custom,pdf_name in zip(dir_customs,pdf_names):\n",
    "for dir_custom in dir_customs:\n",
    "\n",
    "    co=pd.read_csv(root_dir+dir2+'cluster'+dir_custom+'.txt',sep='\\t',header=None)\n",
    "    co.columns=['ACC_NUCCORE']\n",
    "\n",
    "    co_sp = pd.merge(co, ndm_species, how='left', on=['ACC_NUCCORE'])\n",
    "\n",
    "    #co_sp['taxon_genus_name'].value_counts()\n",
    "    unique=co_sp['taxon_genus_name'].value_counts().index\n",
    "    #code, unique= pd.factorize(co_sp.taxon_genus_name)\n",
    "    #print(unique)\n",
    "    \n",
    "    plt.subplot(a, b, c)\n",
    "    #patches, labels, pct_texts=\n",
    "    plt.pie(co_sp['taxon_genus_name'].value_counts(),\n",
    "       # kind='pie',\n",
    "        #autopct=\"%.1f%%\",\n",
    "        colors=colors_sp.loc[unique]['color'].values.tolist(),\n",
    "        #title=\"\",\n",
    "        #explode=[0,0.1,0,0,0],                          \n",
    "        #labels=['']*(len(colors_sp.loc[unique]['color'].values.tolist())),\n",
    "        #textprops = {'fontsize':12,'color':\"black\",'family':'sans-serif'},\n",
    "        #startangle=140,\n",
    "        #rotatelabels=True,\n",
    "        #labeldistance=None,\n",
    "        #pctdistance=0.8,\n",
    "        #wedgeprops = {'linewidth': 0.01,'edgecolor': 'black'}\n",
    "        #rotatelabels=True\n",
    "        #frame=True\n",
    "    )\n",
    "    #rotate the texts\n",
    "    #for label, pct_text in zip(labels, pct_texts):\n",
    "        #pct_text.set_rotation(label.get_rotation())\n",
    "    c=c+1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.legend(colors_sp.loc[unique]['taxon_genus_name'].tolist(),ncol=2,loc='best',prop = {'size':11,'family':'sans-serif'})\n",
    "    \n",
    "\n",
    "\n",
    "#plt.savefig('/root/jupyter_projects/ndm_plasmid_2021/output/aroundNDMcluster_s_85.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
